{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xABx3A-soZMM"
      },
      "source": [
        "# Deep Learning for Video Signal Processing (DLVSP)\n",
        "## Master in Deep Learning for Audio and Video Signal Processing (MUDLAVSP)\n",
        "## Universidad Autonoma de Madrid\n",
        "\n",
        "## **Challenge: multiple object tracking for video sequences (template for assignment)**\n",
        "\n",
        "The goal of this challenge to **is to analyze and improve the tracking performance of the baseline multi-object tracker provided in the tutorial**. Your submission consists on a report in PDF formant and this notebook (plus any additional source code files needed). You can *cut&paste as needed from the tutorial notebook* but please identify clearly your contributions with respect to the tutorial.\n",
        "\n",
        "Your submission should adhere to the following restrictions (see the tutorial for further info on each aspect):\n",
        "* The tracker must be based on the tracking-by-detection scheme, so an object detector must be applied.\n",
        "* For evaluation, you must use the [MOT16](https://motchallenge.net/data/MOT16/) dataset. In particular, you must use the train/test partition provided in the [material](http://www-vpu.eps.uam.es/~jcs/DLVSP/dlvsp_challenge_material.zip') based on the original `MOT16-train` and some other sequences for `test`.\n",
        "* The evaluation should be quantitative employing well-known metrics such as MOTA, MOTP, TP, FP, FN and IDswitches.\n",
        "\n",
        "\n",
        "Author1: Manuel Otero (manuel.otero@estudiante.uam.es)\n",
        "\n",
        "Author2: Javier Mu√±oz (javier.munnozharo@estudiante.uam.es)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFYSSMiwpxSq"
      },
      "source": [
        "# 1 Setup\n",
        "Add here all the required setup and libraries to run your tracker..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRMsynpFU6gh"
      },
      "outputs": [],
      "source": [
        "import torch, torchvision, torchaudio\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from src.tracker.data_track import MOT16Sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1Qe2615tOQQ"
      },
      "source": [
        "# 2 Dataset\n",
        "\n",
        "Add here all the required code to load the dataset...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcbme23UQ5p2"
      },
      "outputs": [],
      "source": [
        "working_dir = '.'\n",
        "\n",
        "#list the contents of the 'train' directory\n",
        "train_dir = os.path.join(working_dir,'data/MOT16/train')\n",
        "\n",
        "#list the contents of the 'test' directory\n",
        "test_dir = os.path.join(working_dir,'data/MOT16/test')\n",
        "\n",
        "seq_name = 'MOT16-04' #uncomment to show a single sequence\n",
        "#seq_name = 'MOT16-train' #uncomment to show one frame for each sequence in the train split\n",
        "#seq_name = 'MOT16-test' #uncomment to show one frame for each sequence in the test split\n",
        "data_dir = os.path.join(working_dir,'data/MOT16')\n",
        "sequences = MOT16Sequences(seq_name, data_dir, load_seg=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cvaNe42gIll"
      },
      "source": [
        "# 3 Object detector\n",
        "Add here all the required code to load the detector employed by the tracker...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2g7oHASTa8v"
      },
      "outputs": [],
      "source": [
        "# path for the source code of the tracker\n",
        "model_dir=os.path.join(working_dir,'models/')\n",
        "#select GPU if available\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "obj_detect_model_file = os.path.join(working_dir, \"models/finetuned_detr_101.model\")\n",
        "#detector has been trained for two classes\n",
        "num_classes=2 # 1 class (person) + background"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# creation of the object detector\n",
        "from src.tracker.object_detector import FRCNN_FPN\n",
        "from src.tracker.detr import DetectionTransformer\n",
        "\n",
        "# object detector\n",
        "obj_detect = DetectionTransformer(num_classes=2)\n",
        "obj_detect_state_dict = torch.load(obj_detect_model_file,map_location=lambda storage, loc: storage)\n",
        "obj_detect.load_state_dict(obj_detect_state_dict)\n",
        "\n",
        "# prints the architecture and sets the model to evaluation mode.\n",
        "obj_detect.eval()\n",
        "\n",
        "# loads detector to CPU or GPU (if available)\n",
        "obj_detect.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGszq40utUfA"
      },
      "source": [
        "# 4 Multi-object tracking\n",
        "Add here all the required code to load and run your tracker..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJ9XnyGCsiqt"
      },
      "outputs": [],
      "source": [
        "#..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2-zvV24JaEO"
      },
      "source": [
        "# 5 Challenge results\n",
        "Add here all the required code to generate the results for the challenge (i.e. to be submitted to Moodle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZLw39nRJa3w"
      },
      "outputs": [],
      "source": [
        "#..."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
